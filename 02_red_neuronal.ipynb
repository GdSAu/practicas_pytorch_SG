{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Neuronal en PyTorch\n",
    "\n",
    "En este notebook veremos como crear una red neuronal usando PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero llamamos a los paquetes necesarios\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import helper\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Ahora lo que necesitamos es un conjunto de datos (dataset). Afortunadamente el paquete **torchvision** provee un conjunto de datos de ejemplo. Utilizaremos MNIST, el cual contiene ejemplos de letras escritas a mano. El siguiente código lee el conjunto de datos y lo separa en un conjunto de entrenamiendo y uno de prueba. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generaramos una transformación para normalizar el conjunto de datos\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                             ])\n",
    "# Descargamos el conjunto de datos de entrenamiento\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "# Cargamos el conjunto\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Descargamos y cargamos el conjunto de prueba\n",
    "testset = datasets.MNIST('MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenamos los datos para tener parejas de imagenes con su respectiva clase\n",
    "\n",
    "# Los datos se encuentran en trainloader asi que generamos un iterador para extraerlos uno por uno\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es recomendable verificar que estamos cargando bien el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb904c83ac8>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');\n",
    "images[1].size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación de la red neuronal\n",
    "\n",
    "Ahora pasaremos a la creación de la red neuronal, como ejemplo utilizaremos una red completamente conectada (fully connected) para clasificar las imagenes de MNIST. Como entrada tendremos 784 nodos = 28 * 28, en seguida tendremos una capa oculta de 128 nodos, con una función de activación tipo RELU, despúes tendremos una segunda capa oculta con 64 nodos y función de activación RELU, en seguida tendremos 10 nodos de salida los cuales pasan por una función softmax que convierte los valores a probabilidades. Finalmente calculamos la pérdida (loss) con la función de entropía cruzada. \n",
    "\n",
    "<img src=\"archivos/net.png\">\n",
    "\n",
    "El modulo que contiene las herramientas para crear la RN es **pytorch.nn**. La red neuronal en sí se crea como una clase que hereda la estructura de **pytorch.nn.Module**. Cada una de las capas de la red se define de forma independiente. e.g. Para crear una capa con 784 entradas y 128 nodos utilizamos *nn.Linear(784, 128)*\n",
    "\n",
    "La red implementa la función *forward* que realiza el paso frontal (fowdward pass). Esta función miembro recibe un tensor como emtrada y calcula la salida de la red. \n",
    "\n",
    "Varias funciones de activación se encuntran en el módulo *nn.functional*. Dicho módulo usualmente se importa como *F*. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Definir las capas. Cada una con 128, 64 y 10 unidades respectivamente\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        # Capa de salida con 10 units (una para cada dígito)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ''' Pase frontal de la red, regresamos las probabilidades '''\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicializamos pesos y sesgos\n",
    "\n",
    "Cuando creas las capas se crean también los tensores correspondientes a los pesos y sesgos. Éstos son inicializados por ti, aunque pudes modificarlos usando funciones extra. Para observar sus valores puedes llamar a *model.fc1.weight* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0165,  0.0076,  0.0262,  ..., -0.0338, -0.0274,  0.0004],\n",
      "        [ 0.0310,  0.0161, -0.0259,  ..., -0.0172,  0.0103,  0.0138],\n",
      "        [-0.0201, -0.0247,  0.0063,  ...,  0.0017,  0.0275,  0.0191],\n",
      "        ...,\n",
      "        [ 0.0058, -0.0259, -0.0033,  ..., -0.0011, -0.0334, -0.0328],\n",
      "        [-0.0169,  0.0164,  0.0039,  ..., -0.0129,  0.0009,  0.0007],\n",
      "        [-0.0331, -0.0253, -0.0105,  ...,  0.0030, -0.0121, -0.0289]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0286, -0.0132, -0.0294,  0.0129,  0.0172,  0.0176, -0.0137, -0.0028,\n",
      "        -0.0308,  0.0054,  0.0344,  0.0027,  0.0206, -0.0282, -0.0302, -0.0214,\n",
      "        -0.0215,  0.0169,  0.0319,  0.0271, -0.0082,  0.0293, -0.0207, -0.0138,\n",
      "         0.0207,  0.0099, -0.0246,  0.0287, -0.0207,  0.0278,  0.0203,  0.0296,\n",
      "         0.0192, -0.0218, -0.0309, -0.0350, -0.0231,  0.0013,  0.0218, -0.0105,\n",
      "        -0.0304, -0.0189, -0.0113,  0.0014,  0.0071, -0.0020, -0.0005,  0.0012,\n",
      "         0.0168, -0.0016,  0.0326,  0.0061,  0.0254, -0.0323,  0.0200, -0.0207,\n",
      "         0.0153, -0.0086, -0.0025,  0.0068, -0.0090,  0.0133, -0.0219, -0.0127,\n",
      "         0.0114, -0.0255,  0.0147, -0.0014,  0.0160,  0.0207,  0.0088, -0.0026,\n",
      "         0.0149,  0.0073, -0.0100,  0.0042,  0.0078,  0.0305,  0.0078,  0.0294,\n",
      "         0.0342,  0.0287,  0.0132, -0.0341,  0.0180,  0.0032,  0.0177, -0.0190,\n",
      "         0.0341,  0.0010, -0.0137, -0.0331, -0.0257,  0.0086, -0.0208,  0.0243,\n",
      "         0.0166, -0.0151,  0.0009, -0.0143, -0.0353,  0.0230,  0.0329, -0.0040,\n",
      "         0.0156, -0.0112, -0.0142,  0.0071,  0.0072,  0.0272,  0.0256,  0.0137,\n",
      "        -0.0286,  0.0058,  0.0353,  0.0314, -0.0311, -0.0329,  0.0314,  0.0280,\n",
      "         0.0140, -0.0090, -0.0041,  0.0133, -0.0054, -0.0353,  0.0276,  0.0054],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.fc1.weight)\n",
    "print(model.fc1.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que deseamos inicializar los pesos con algunos valores personalizados. Dado que los pesos y sesgos en sí son variables de autograd (optimizador) necesitamos convertirlos a tensores para poder modificarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Colocamos ceros\n",
    "model.fc1.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0001, -0.0176, -0.0116,  ..., -0.0152, -0.0002, -0.0166],\n",
       "        [-0.0048, -0.0030, -0.0006,  ..., -0.0063, -0.0022,  0.0078],\n",
       "        [-0.0231,  0.0069,  0.0086,  ...,  0.0260,  0.0083, -0.0059],\n",
       "        ...,\n",
       "        [-0.0105, -0.0006, -0.0041,  ...,  0.0047, -0.0003,  0.0081],\n",
       "        [-0.0018, -0.0046, -0.0135,  ..., -0.0140, -0.0046,  0.0054],\n",
       "        [-0.0112,  0.0002, -0.0001,  ...,  0.0307, -0.0051, -0.0113]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# muestreamos de una distribución normal con media cero y desv. estandar = 0.01\n",
    "model.fc1.weight.data.normal_(std=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pase frontal\n",
    "\n",
    "Hasta el momento la red no está entrenada y solo tenemos los pesos aleatorios. Hagamos un pase frontal para ver que pasa. Primero debemos convertir la imagen a un tensor y pasarla a través de la red. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtengamos el siguiente valor \n",
    "#dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Reestructuremos la imagen a un vector de una dimensión, hay quie le llama a esta operación \"aplanado\".\n",
    "# La nueva forma será (batch size, color channels, image pixels) \n",
    "images.resize_(64, 1, 784)\n",
    "# alternativa: images.resize_(images.shape[0], 1, 784) to not automatically get batch size\n",
    "\n",
    "# Pase frontal de la red\n",
    "img_idx = 0\n",
    "ps = model.forward(images[img_idx,:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1069, 0.1073, 0.0943, 0.1041, 0.0886, 0.0924, 0.1074, 0.1048, 0.1030,\n",
       "         0.0912]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps\n",
    "\n",
    "#img = images[img_idx]\n",
    "#helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muy probablemente ninguna de las clases tiene una probabilidad grande con respecto de las otras, esto se debe a que todavía no hemos entrenado la red. En el siguiente ejercicio entrenaremos la red.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
