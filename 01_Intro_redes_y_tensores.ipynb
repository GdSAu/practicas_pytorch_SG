{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "\n",
    "## Redes Neuronales\n",
    "\n",
    "Las redes neuronales son un modelo matemático que nos permite aproximar una función. Tienen similitud a las neuronas del cerebro en el sentido que ambas reciben varias entradas, realizan un cálculo y determinan una salida la cual es entrada para otras neuronas. \n",
    "\n",
    "En la siguiente imagen encontrarás una neurona simple, también conocida como perceptrón.\n",
    "\n",
    "<img src=\"archivos/simple_neuron.png\">\n",
    "Imagen tomada de [Udacity]\n",
    "\n",
    "\n",
    "Podemos ver la salida del perceptrón como una secuencia de operaciones, primero se calcula $h$ a partir del producto punto, entre las entradas $X$ y los pesos $W$, sumado a el sesgo $b$, es decir\n",
    "\n",
    "$$h = MX + b$$\n",
    "\n",
    "despúes se 'pasa' $h$ por una función de activación que transforma el valor,\n",
    "\n",
    "$$y = f(h)$$\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensores en Pytorch\n",
    "\n",
    "Los tensores son una generalización de los vectores y matrices. Cuando hablamos de un tensor de una dimensión nos estamos refierendo a un vector que puede tener $n$ elementos. Podemos tener tensores de varias dimensiones, por ejemplo una matriz 2D sería un tensor 2D y así sucesivamente. Los tensores son la base de muchos paquetes de para programar deep learning, debido a que las redes neuronales son ¡un montón de operaciones matriciales!, además mantienen la conección en el grafo y permiten la implementación del gradiente descendiente. Asi que es indispensable tener una representación adecuada para reducir el tiempo de entrenamiento. \n",
    "\n",
    "Sin más preámbulo vayamos a la programación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.21.5\n",
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "# Primero importemos los paquetes necesarios\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "print(np.__version__)\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzemos a explorar los tensores. Creemos unos tensores y realizemos algunas opereaciones entre ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor de 4 por 2 elementos relleno de unos\n",
    "y = torch.ones(4,2)\n",
    "\n",
    "r = torch.ones(3,3)\n",
    "\n",
    "print(y)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.],\n",
      "        [3., 3.],\n",
      "        [3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "# operación entre tensores\n",
    "\n",
    "z = y + y + y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# acceder a los elementos de un tensor\n",
    "z[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.],\n",
       "        [3.],\n",
       "        [3.],\n",
       "        [3.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape\n",
    "\n",
    "Una de las cosas más comunes que realizaŕas con los tensores es consultar su 'forma' es decir, la cantidad de elementos que hay en él, para tal función existe *.size()* \n",
    "\n",
    "Si deseamos cambiar la forma del tensor entonces utilizaremos *.resize_()* Observa que el guión bajo indica que se va a modificar el tensor en sí, si no utilizamos el guión bajo se creará un nuevo tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.0000e+00, 3.0000e+00, 3.0000e+00],\n",
       "        [3.0000e+00, 3.0000e+00, 3.0000e+00],\n",
       "        [3.0000e+00, 3.0000e+00, 5.8451e-36]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.resize_(3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pasando Tensores a Numpy\n",
    "\n",
    "Antes de hacer el entrenamiento de una red es muy probable que tengamos que hacer un preprocesamiento de los datos. Usualmente, el procesamiento se hace en numpy por facilidad además que tenemos muchísimas herramientas disponibles. Afortunadamente, pytorch provee una funciones para poder convertir entre formatos de forma casi directa. Para convetir de numpy a tensor usamos *torch.from_numpy()* y para retornar de torch a numpy utilizamos el método *.numpy()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4377701  0.33680366 0.60851603]\n",
      " [0.2469644  0.27644237 0.24265467]\n",
      " [0.05666639 0.67005403 0.85289563]\n",
      " [0.68112643 0.20200113 0.08391637]]\n"
     ]
    }
   ],
   "source": [
    "# generemos un array en numpy\n",
    "a = np.random.rand(4,3)\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4378, 0.3368, 0.6085],\n",
      "        [0.2470, 0.2764, 0.2427],\n",
      "        [0.0567, 0.6701, 0.8529],\n",
      "        [0.6811, 0.2020, 0.0839]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# convertir a pytorch\n",
    "A = torch.from_numpy(a)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4377701  0.33680366 0.60851603]\n",
      " [0.2469644  0.27644237 0.24265467]\n",
      " [0.05666639 0.67005403 0.85289563]\n",
      " [0.68112643 0.20200113 0.08391637]]\n"
     ]
    }
   ],
   "source": [
    "# convertir a numpy\n",
    "b = A.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advertencia! Ten cuidado por que resulta que las variables convertidas de pytorch a numpy comparte memoria asi que si modificas uno se modificará el otro!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4378, 0.3368, 0.6085],\n",
      "        [0.2470, 0.2764, 0.2427],\n",
      "        [0.0567, 0.6701, 0.8529],\n",
      "        [0.6811, 0.2020, 0.0839]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8755, 0.6736, 1.2170],\n",
      "        [0.4939, 0.5529, 0.4853],\n",
      "        [0.1133, 1.3401, 1.7058],\n",
      "        [1.3623, 0.4040, 0.1678]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# multipliquemos el tensor\n",
    "A.mul_(2)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ahora observemos el array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8755402 , 0.67360732, 1.21703206],\n",
       "       [0.4939288 , 0.55288474, 0.48530935],\n",
       "       [0.11333279, 1.34010805, 1.70579126],\n",
       "       [1.36225285, 0.40400226, 0.16783275]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptrón\n",
    "\n",
    "Ejercicio: implementa un perceptrón utilizando funciones de PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor([2., 3., 4.], dtype=torch.float64)\n",
      "tensor([0.1000, 0.1000, 0.2000], dtype=torch.float64)\n",
      "tensor([1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Implementa un perceptrón\n",
    "x_np = np.array([2.0, 3.0, 4.0])\n",
    "w_np = np.array([0.1, 0.1, 0.2])\n",
    "b_np = np.array([1.0])\n",
    "\n",
    "# en numpy seria\n",
    "h_np = None\n",
    "print(h_np)\n",
    "\n",
    "# Convierte los vectores a tensores de pytorch\n",
    "X = torch.from_numpy(x_np)\n",
    "print(X)\n",
    "W = torch.from_numpy(w_np)\n",
    "print(W)\n",
    "B = torch.from_numpy(b_np)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.3000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# realiza las operaciones necesarias y calcula la combinación lineal h\n",
    "# algunas funciones útiles son torch.add() y torch.dot()\n",
    "H =  torch.add(torch.dot(W,X),B)\n",
    "print(H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9089], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Pasa h por la función de activación segmoide torch.sigmoid()\n",
    "Y = torch.sigmoid(H)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90887704]\n"
     ]
    }
   ],
   "source": [
    "# Finalmente regresamos el tensor a un array de numpy\n",
    "y_np = Y.numpy()\n",
    "print(y_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practicas_pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "e22d029f5570ef7df543599926afc42bb090457ba5a887f8aae20fd6018d0da0"
   }
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
